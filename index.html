<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Awesome GE2EAD - General End-to-End Autonomous Driving Survey</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <!-- Theme Toggle -->
    <button class="theme-toggle" id="themeToggle" aria-label="Toggle theme">
        <span class="theme-icon">üåô</span>
    </button>

    <!-- Hero Section -->
    <section class="hero">
        <div class="hero-overlay"></div>
        <div class="hero-content">
            <h1 class="hero-title">
                <span class="hero-title-line">Awesome GE2EAD</span>
                <span class="hero-subtitle">Survey of General End-to-End Autonomous Driving</span>
            </h1>
            <p class="hero-description">
                A Unified Perspective on the Future of Autonomous Driving
            </p>
            <div class="hero-actions">
                <a href="https://doi.org/10.36227/techrxiv.176523315.56439138/v1" target="_blank" class="hero-btn primary">
                    <span>üìÑ</span> Read Paper
                </a>
                <a href="https://github.com/AutoLab-SAI-SJTU/GE2EAD" target="_blank" class="hero-btn secondary">
                    <span>üíª</span> GitHub Repo
                </a>
            </div>
        </div>
        <div class="scroll-indicator">
            <span>Scroll to explore</span>
            <div class="scroll-arrow">‚Üì</div>
        </div>
    </section>

    <div class="container">
        <!-- Research Overview Section -->
        <section class="research-overview">
            <h2 class="section-title">Research Landscape</h2>
            <div class="overview-grid single">
                <div class="overview-card">
                    <embed src="images/coggle.pdf" type="application/pdf" class="overview-pdf">
                    <h3>Research Mindmap</h3>
                    <p>Comprehensive visualization of the GE2EAD research landscape</p>
                    <a href="images/coggle.pdf" target="_blank" class="view-fullscreen">üîç View Fullscreen</a>
                </div>
            </div>
        </section>

        <!-- Featured Papers Section -->
        <section class="featured-section">
            <h2 class="section-title">üåü Featured Papers</h2>
            <div class="featured-carousel">
                <div class="featured-card">
                    <div class="featured-content">
                        <div class="featured-badge">NeurIPS 2025</div>
                        <h3>DiffusionDriveV2</h3>
                        <p class="featured-desc">Reinforcement Learning-Constrained Truncated Diffusion Modeling in End-to-End Autonomous Driving.</p>
                        <div class="featured-tags">
                            <span class="tag">Diffusion</span>
                            <span class="tag">RL</span>
                        </div>
                        <div class="featured-links">
                            <a href="https://arxiv.org/abs/2512.07745" target="_blank">üìÑ Paper</a>
                            <a href="https://github.com/hustvl/DiffusionDriveV2" target="_blank">üíª Code</a>
                        </div>
                    </div>
                </div>
                <div class="featured-card">
                    <div class="featured-content">
                        <div class="featured-badge">2025</div>
                        <h3>CoT4AD</h3>
                        <p class="featured-desc">Vision-Language-Action Model with Explicit Chain-of-Thought Reasoning for Autonomous Driving.</p>
                        <div class="featured-tags">
                            <span class="tag">VLA</span>
                            <span class="tag">CoT</span>
                        </div>
                        <div class="featured-links">
                            <a href="https://www.arxiv.org/pdf/2511.22532" target="_blank">üìÑ Paper</a>
                        </div>
                    </div>
                </div>
                <div class="featured-card">
                    <div class="featured-content">
                        <div class="featured-badge">ICCV 2025</div>
                        <h3>AdaDrive</h3>
                        <p class="featured-desc">Self-Adaptive Slow-Fast System for Language-Grounded Autonomous Driving.</p>
                        <div class="featured-tags">
                            <span class="tag">LLM</span>
                            <span class="tag">Adaptive</span>
                        </div>
                        <div class="featured-links">
                            <a href="https://arxiv.org/pdf/2511.06253" target="_blank">üìÑ Paper</a>
                            <a href="https://github.com/ReaFly/AdaDrive" target="_blank">üíª Code</a>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Conventional Section -->
        <section id="conventional" class="papers-section">
            <h2 class="section-title">üöó Conventional Methods</h2>
            <div class="papers-grid">
                <!-- Paper 1 -->
                <div class="paper-card" data-year="2025">
                    <div class="paper-header">
                        <h4>DiffusionDriveV2</h4>
                        <div class="paper-venue">NeurIPS 2025</div>
                    </div>
                    <p class="paper-description">Reinforcement Learning-Constrained Truncated Diffusion Modeling</p>
                    <div class="paper-tags"><span class="tag">Diffusion</span><span class="tag">RL</span></div>
                    <div class="paper-links">
                        <a href="https://arxiv.org/abs/2512.07745" target="_blank" class="paper-link">üìÑ Paper</a>
                        <a href="https://github.com/hustvl/DiffusionDriveV2" target="_blank" class="paper-link">üíª Code</a>
                    </div>
                </div>
                <!-- Paper 2 -->
                <div class="paper-card" data-year="2025">
                    <div class="paper-header">
                        <h4>SIMSCALE</h4>
                        <div class="paper-venue">2025</div>
                    </div>
                    <p class="paper-description">SimScale: Learning to Drive via Real-World Simulation at Scale</p>
                    <div class="paper-tags"><span class="tag">Simulation</span><span class="tag">Data Gen</span></div>
                    <div class="paper-links">
                        <a href="https://arxiv.org/abs/2511.23369" target="_blank" class="paper-link">üìÑ Paper</a>
                        <a href="https://github.com/OpenDriveLab/SimScale" target="_blank" class="paper-link">üíª Code</a>
                    </div>
                </div>
                <!-- Paper 3 -->
                <div class="paper-card" data-year="2025">
                    <div class="paper-header">
                        <h4>SeerDrive</h4>
                        <div class="paper-venue">NeurIPS 2025</div>
                    </div>
                    <p class="paper-description">Future-Aware End-to-End Driving: Bidirectional Modeling</p>
                    <div class="paper-tags"><span class="tag">World Model</span><span class="tag">Planning</span></div>
                    <div class="paper-links">
                        <a href="https://arxiv.org/abs/2510.11092" target="_blank" class="paper-link">üìÑ Paper</a>
                        <a href="https://github.com/LogosRoboticsGroup/SeerDrive" target="_blank" class="paper-link">üíª Code</a>
                    </div>
                </div>
            </div>
            <p class="show-more">
                <a href="https://github.com/AutoLab-SAI-SJTU/GE2EAD#conventional-end-to-end-methods" target="_blank">
                    View all Conventional papers on GitHub ‚Üí
                </a>
            </p>
        </section>

        <!-- VLM Section -->
        <section id="vlm-centric" class="papers-section">
            <h2 class="section-title">ü§ñ VLM-Centric Methods</h2>
            <div class="papers-grid">
                <!-- Paper 1 -->
                <div class="paper-card" data-year="2025">
                    <div class="paper-header">
                        <h4>CoT4AD</h4>
                        <div class="paper-venue">2025</div>
                    </div>
                    <p class="paper-description">Vision-Language-Action Model with Explicit Chain-of-Thought Reasoning</p>
                    <div class="paper-tags"><span class="tag">VLA</span><span class="tag">CoT</span></div>
                    <div class="paper-links">
                        <a href="https://www.arxiv.org/pdf/2511.22532" target="_blank" class="paper-link">üìÑ Paper</a>
                    </div>
                </div>
                <!-- Paper 2 -->
                <div class="paper-card" data-year="2025">
                    <div class="paper-header">
                        <h4>MPA</h4>
                        <div class="paper-venue">NeurIPS 2025</div>
                    </div>
                    <p class="paper-description">Model-Based Policy Adaptation for Closed-Loop End-to-End Autonomous Driving</p>
                    <div class="paper-tags"><span class="tag">Model-Based</span><span class="tag">Sim</span></div>
                    <div class="paper-links">
                        <a href="https://arxiv.org/abs/2511.21584" target="_blank" class="paper-link">üìÑ Paper</a>
                    </div>
                </div>
                <!-- Paper 3 -->
                <div class="paper-card" data-year="2025">
                    <div class="paper-header">
                        <h4>Alpamayo-R1</h4>
                        <div class="paper-venue">2025</div>
                    </div>
                    <p class="paper-description">Bridging Reasoning and Action Prediction for Generalizable Autonomous Driving</p>
                    <div class="paper-tags"><span class="tag">VLA</span><span class="tag">Reasoning</span></div>
                    <div class="paper-links">
                        <a href="https://arxiv.org/abs/2511.00088" target="_blank" class="paper-link">üìÑ Paper</a>
                        <a href="https://github.com/NVlabs/alpamayo" target="_blank" class="paper-link">üíª Code</a>
                    </div>
                </div>
            </div>
            <p class="show-more">
                <a href="https://github.com/AutoLab-SAI-SJTU/GE2EAD#vlm-centric-end-to-end-methods" target="_blank">
                    View all VLM-centric papers on GitHub ‚Üí
                </a>
            </p>
        </section>

        <!-- Hybrid Section -->
        <section id="hybrid" class="papers-section">
            <h2 class="section-title">üîÑ Hybrid Methods</h2>
            <div class="papers-grid">
                <!-- Paper 1 -->
                <div class="paper-card" data-year="2025">
                    <div class="paper-header">
                        <h4>AdaDrive</h4>
                        <div class="paper-venue">ICCV 2025</div>
                    </div>
                    <p class="paper-description">Self-Adaptive Slow-Fast System for Language-Grounded Autonomous Driving</p>
                    <div class="paper-tags"><span class="tag">Slow-Fast</span><span class="tag">LLM</span></div>
                    <div class="paper-links">
                        <a href="https://arxiv.org/abs/2511.06253" target="_blank" class="paper-link">üìÑ Paper</a>
                        <a href="https://github.com/ReaFly/AdaDrive" target="_blank" class="paper-link">üíª Code</a>
                    </div>
                </div>
                <!-- Paper 2 -->
                <div class="paper-card" data-year="2025">
                    <div class="paper-header">
                        <h4>ReAL-AD</h4>
                        <div class="paper-venue">2025</div>
                    </div>
                    <p class="paper-description">Towards Human-Like Reasoning in End-to-End Autonomous Driving</p>
                    <div class="paper-tags"><span class="tag">Reasoning</span><span class="tag">VLM</span></div>
                    <div class="paper-links">
                        <a href="https://arxiv.org/abs/2507.12499" target="_blank" class="paper-link">üìÑ Paper</a>
                        <a href="https://4dvlab.github.io/project_page/realad" target="_blank" class="paper-link">üåê Project</a>
                    </div>
                </div>
            </div>
            <p class="show-more">
                <a href="https://github.com/AutoLab-SAI-SJTU/GE2EAD#hybrid-end-to-end-methods" target="_blank">
                    View all Hybrid papers on GitHub ‚Üí
                </a>
            </p>
        </section>

        <!-- Datasets Section -->
        <section id="datasets" class="datasets-section">
            <h2 class="section-title">üìä Datasets</h2>
            <div class="dataset-grid">
                <div class="dataset-card">
                    <div class="dataset-icon">üéØ</div>
                    <h4>OmniDrive</h4>
                    <p class="dataset-year">CVPR 2025</p>
                    <p class="dataset-desc">Holistic Vision-Language Dataset with Counterfactual Reasoning</p>
                    <div class="dataset-links">
                        <a href="https://arxiv.org/abs/2405.01533" target="_blank">Paper</a>
                        <a href="https://github.com/NVlabs/OmniDrive" target="_blank">Dataset</a>
                    </div>
                </div>
                <div class="dataset-card">
                    <div class="dataset-icon">üé¨</div>
                    <h4>CoVLA</h4>
                    <p class="dataset-year">WACV 2025</p>
                    <p class="dataset-desc">Comprehensive Vision-Language-Action Dataset</p>
                    <div class="dataset-links">
                        <a href="https://arxiv.org/abs/2408.10845" target="_blank">Paper</a>
                        <a href="https://huggingface.co/datasets/turing-motors/CoVLA-Dataset" target="_blank">Dataset</a>
                    </div>
                </div>
                <div class="dataset-card">
                    <div class="dataset-icon">üåê</div>
                    <h4>nuScenes</h4>
                    <p class="dataset-year">CVPR 2020</p>
                    <p class="dataset-desc">A Multimodal Dataset for Autonomous Driving</p>
                    <div class="dataset-links">
                        <a href="https://arxiv.org/abs/1903.11027" target="_blank">Paper</a>
                        <a href="https://www.nuscenes.org/" target="_blank">Dataset</a>
                    </div>
                </div>
            </div>
            <p class="show-more">
                <a href="https://github.com/AutoLab-SAI-SJTU/GE2EAD#dataset" target="_blank">
                    View all Datasets on GitHub ‚Üí
                </a>
            </p>
        </section>

        <!-- Footer -->
        <footer>
            <div class="citation">
                <h3>üìñ Citation</h3>
                <p>If you find this resource useful, please consider citing:</p>
                <pre><code>@article{yang2025survey,
  title={Survey of General End-to-End Autonomous Driving: A Unified Perspective},
  author={Yang, Yixiang and Han, Chuanrong and Mao, Runhao and others},
  journal={TechRxiv},
  year={2025},
  month={December},
  doi={10.36227/techrxiv.176523315.56439138/v1}
}</code></pre>
            </div>
            <p class="footer-note">
                ¬© 2025 AutoLab-SAI-SJTU. Released under Apache 2.0 License.
            </p>
        </footer>
    </div>

    <script src="script.js"></script>
</body>
</html>